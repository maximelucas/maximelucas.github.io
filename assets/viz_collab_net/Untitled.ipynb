{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7886e385",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pybtex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# import necessary libraries\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpybtex\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bibtex  \u001b[38;5;66;03m# for reading the bib files\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# some auxiliary functions\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# you migth have to add further repalcement rules\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlatex2unicode\u001b[39m(latexString):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pybtex'"
     ]
    }
   ],
   "source": [
    "## some options\n",
    "inputBibFileName = \"../../_bibliography/papers.bib\"\n",
    "outputJSONFileName = \"collab_net.json\"\n",
    "#\n",
    "authorInformationFile = (\n",
    "    \"\"  #'authorinfoRosalindFranklin.csv' # optional co-author information\n",
    ")\n",
    "deleteEgoNode = False\n",
    "##\n",
    "\n",
    "import csv  # for loading comma seperated values\n",
    "import json  # for writing the json\n",
    "import re\n",
    "\n",
    "# import necessary libraries\n",
    "from pybtex.database.input import bibtex  # for reading the bib files\n",
    "\n",
    "\n",
    "# some auxiliary functions\n",
    "# you migth have to add further repalcement rules\n",
    "def latex2unicode(latexString):\n",
    "    \"\"\"takes the name of an author as string and return the string\n",
    "    with latex character replaced as normal string for the HTML\"\"\"\n",
    "    latexString = latexString.replace('{\\\\\"u}', \"ü\")\n",
    "    latexString = latexString.replace(\"{\\\\'o}\", \"ó\")\n",
    "    latexString = latexString.replace(\"{\\\\'a}\", \"á\")\n",
    "    latexString = latexString.replace(\"{\\\\~a}\", \"ã\")\n",
    "\n",
    "    return latexString\n",
    "\n",
    "\n",
    "# some preperation to read the bibtex file\n",
    "parser = bibtex.Parser()\n",
    "bib_data = parser.parse_file(inputBibFileName)\n",
    "\n",
    "pyenv\n",
    "listOfAuthors = []  # empty list of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3960820-8557-4108-b918-f56a5181ce98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------\n",
      "anyio                     4.4.0\n",
      "argon2-cffi               23.1.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "arrow                     1.3.0\n",
      "asttokens                 2.4.1\n",
      "async-lru                 2.0.4\n",
      "attrs                     23.2.0\n",
      "autopep8                  2.3.1\n",
      "Babel                     2.15.0\n",
      "beautifulsoup4            4.12.3\n",
      "black                     24.4.2\n",
      "bleach                    6.1.0\n",
      "certifi                   2024.7.4\n",
      "cffi                      1.16.0\n",
      "charset-normalizer        3.3.2\n",
      "click                     8.1.7\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.0\n",
      "cycler                    0.12.1\n",
      "debugpy                   1.8.2\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.0.1\n",
      "fastjsonschema            2.20.0\n",
      "fonttools                 4.53.1\n",
      "fqdn                      1.5.1\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.5\n",
      "httpx                     0.27.0\n",
      "idna                      3.7\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.26.0\n",
      "isoduration               20.11.0\n",
      "isort                     5.13.2\n",
      "jedi                      0.19.1\n",
      "Jinja2                    3.1.4\n",
      "json5                     0.9.25\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.22.0\n",
      "jsonschema-specifications 2023.12.1\n",
      "jupyter_client            8.6.2\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.10.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.14.1\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.2.3\n",
      "jupyterlab_code_formatter 2.2.1\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.2\n",
      "kiwisolver                1.4.5\n",
      "latexcodec                3.0.0\n",
      "MarkdownSlides            1.6\n",
      "MarkupSafe                2.1.5\n",
      "matplotlib                3.9.2\n",
      "matplotlib-inline         0.1.7\n",
      "mistune                   3.0.2\n",
      "mypy-extensions           1.0.0\n",
      "nbclient                  0.10.0\n",
      "nbconvert                 7.16.4\n",
      "nbformat                  5.10.4\n",
      "nbopen                    0.7\n",
      "nbqa                      1.8.5\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.3\n",
      "notebook                  7.2.1\n",
      "notebook_shim             0.2.4\n",
      "numpy                     2.1.0\n",
      "overrides                 7.7.0\n",
      "packaging                 24.1\n",
      "pandas                    2.2.2\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.4\n",
      "pathspec                  0.12.1\n",
      "pexpect                   4.9.0\n",
      "pillow                    10.4.0\n",
      "pip                       24.0\n",
      "platformdirs              4.2.2\n",
      "prometheus_client         0.20.0\n",
      "prompt_toolkit            3.0.47\n",
      "psutil                    6.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.2\n",
      "pybtex                    0.24.0\n",
      "pycodestyle               2.12.0\n",
      "pycparser                 2.22\n",
      "Pygments                  2.18.0\n",
      "pyparsing                 3.1.4\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        2.0.7\n",
      "pytz                      2024.1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     26.0.3\n",
      "referencing               0.35.1\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rpds-py                   0.18.1\n",
      "ruff                      0.5.1\n",
      "scipy                     1.14.1\n",
      "seaborn                   0.13.2\n",
      "Send2Trash                1.8.3\n",
      "setuptools                65.5.0\n",
      "six                       1.16.0\n",
      "sniffio                   1.3.1\n",
      "soupsieve                 2.5\n",
      "stack-data                0.6.3\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.3.0\n",
      "tokenize-rt               5.2.0\n",
      "tomli                     2.0.1\n",
      "tornado                   6.4.1\n",
      "traitlets                 5.14.3\n",
      "types-python-dateutil     2.9.0.20240316\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2024.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.2.2\n",
      "wcwidth                   0.2.13\n",
      "webcolors                 24.6.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "xgi                       0.8.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d30fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "for paperKeys in bib_data.entries.keys():\n",
    "    # convert author names to strings and remove * for co-first\n",
    "    thors = [latex2unicode(str(author)) for author in bib_data.entries[paperKeys].persons[\"author\"] ]\n",
    "    thors = [author.replace(\"*\", \"\") for author in thors]\n",
    "    bib_data.entries[paperKeys].persons[\"author\"] = thors\n",
    "    # remove latex formatting from titles \"{}\"\n",
    "    title = bib_data.entries[paperKeys].fields[\"title\"]\n",
    "    title = title.replace(\"{\", \"\")\n",
    "    title = title.replace(\"}\", \"\")\n",
    "    bib_data.entries[paperKeys].fields[\"title\"] = title\n",
    "    \n",
    "print(bib_data.entries[paperKeys].persons[\"author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34224a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfAuthors = []  # empty list of authors\n",
    "\n",
    "# go throuh all entries\n",
    "for paperKeys in bib_data.entries.keys():\n",
    "    # get the authors of this paper\n",
    "\n",
    "    # authors = bib_data.entries[paperKeys].persons['author'].split(\" and \")\n",
    "    # save them to the list of authors\n",
    "    for author in bib_data.entries[paperKeys].persons[\"author\"]:\n",
    "        listOfAuthors.append(str(author))\n",
    "\n",
    "listOfAuthors\n",
    "\n",
    "# remove * for co-first \n",
    "#listOfAuthors = [author.replace(\"*\", \"\") for author in listOfAuthors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if deleteEgoNode == True:\n",
    "    # we assume that the author with the most entries is the ego node and delete it\n",
    "    egoNode = max(listOfAuthors, key=listOfAuthors.count)  # returns the ego node\n",
    "    listOfAuthors = list(set(listOfAuthors))  # gets unique list of authors\n",
    "    listOfAuthors.pop(\n",
    "        listOfAuthors.index(egoNode)\n",
    "    )  # deletes it from the list of authors\n",
    "    print(\"Removing the ego node: %s \" % egoNode)\n",
    "else:\n",
    "    listOfAuthors = list(set(listOfAuthors))  # gets unique list of authors\n",
    "\n",
    "nAuthors = len(listOfAuthors)  # number of author nodes\n",
    "nPapers = len(bib_data.entries.keys())  # number of paper nodes\n",
    "\n",
    "\n",
    "# read the additional author information from the csv\n",
    "authorLinks_dict = {}  # create an empty dictionary\n",
    "authorImage_dict = {}  # create an empty dictionary\n",
    "\n",
    "try:\n",
    "    authorInfo_reader = csv.DictReader(open(authorInformationFile))\n",
    "    for row in authorInfo_reader:\n",
    "        authorLinks_dict[row[\"name\"]] = row[\"url\"]\n",
    "        authorImage_dict[row[\"name\"]] = row[\"image\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"no optional co-author information available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d8bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary reflecting the graph (there are more pythonic ways\n",
    "# possible to creat this, e.g., with zip, but this is easiest)\n",
    "\n",
    "node_list = []\n",
    "# create author nodes\n",
    "for i in range(nAuthors):\n",
    "    node_dict = {}  # create an empty dictionary for this node\n",
    "    node_dict[\"id\"] = \"A\" + str(i)\n",
    "    node_dict[\"group\"] = 0\n",
    "    # invert the name such that the given name is before the last name\n",
    "    try:  # we need this try to deal with single author papers\n",
    "        authorSplit = listOfAuthors[i].split(\",\")\n",
    "        nameThisAuthor = authorSplit[1][1::] + \" \" + authorSplit[0]\n",
    "    except:\n",
    "        authorSplit = listOfAuthors[i]\n",
    "        nameThisAuthor = authorSplit[1][1::] + \" \" + authorSplit[0]\n",
    "\n",
    "    nameThisAuthorUnicode = latex2unicode(nameThisAuthor)\n",
    "    print(nameThisAuthorUnicode)\n",
    "    node_dict[\"name\"] = nameThisAuthorUnicode\n",
    "    node_list.append(node_dict)\n",
    "    # try to set the url for this author but default is google it\n",
    "    node_dict[\"url\"] = \"https://www.google.com/search?q=\" + nameThisAuthor\n",
    "    try:\n",
    "        if authorLinks_dict[nameThisAuthor] is None:\n",
    "            raise KeyError(\"no information for this author\")\n",
    "        else:\n",
    "            node_dict[\"url\"] = authorLinks_dict[nameThisAuthor]\n",
    "    except KeyError:\n",
    "        node_dict[\"url\"] = \"https://www.google.com/search?q=\" + nameThisAuthor\n",
    "\n",
    "        # try to set a image for this author\n",
    "    try:\n",
    "        node_dict[\"image\"] = authorImage_dict[nameThisAuthor]\n",
    "    except KeyError:  # if no image jsut leave blank\n",
    "        node_dict[\"image\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the links between the nodes\n",
    "link_list = []\n",
    "i=0\n",
    "for paperKeys in bib_data.entries.keys(): # go over every paper\n",
    "    # create the paper node\n",
    "    node_dict = {} # create an empty dictionary for this node\n",
    "    node_dict[\"id\"] = \"P\" + str(i)\n",
    "    node_dict[\"group\"] = 1\n",
    "    thisPaperName = bib_data.entries[paperKeys].fields['title']\n",
    "    # remove curly bracket in paper name, remove it\n",
    "    if thisPaperName[0]=='{':\n",
    "        thisPaperName=thisPaperName[1:-1]\n",
    "    node_dict[\"name\"] =  thisPaperName\n",
    "    node_list.append(node_dict)\n",
    "\n",
    "    # set image for this paper\n",
    "    try:\n",
    "        node_dict[\"image\"] = bib_data.entries[paperKeys].fields['image']\n",
    "    except KeyError: # if no image just leave blank\n",
    "        node_dict[\"image\"] = []\n",
    "\n",
    "\n",
    "    # find the authors for this paper\n",
    "    authorsThisPaper = [str(i).split('*')[0].strip() for i in bib_data.entries[paperKeys].persons['author']]\n",
    "\n",
    "    # if the paper has a url, add it\n",
    "    try:\n",
    "        node_dict[\"url\"] = bib_data.entries[paperKeys].fields['url']\n",
    "    except KeyError: # otherwise refer to google\n",
    "        node_dict[\"url\"] = \"https://www.google.com/search?q=\" + bib_data.entries[paperKeys].fields['title']\n",
    "\n",
    "\n",
    "    for authors in authorsThisPaper:\n",
    "        link_dict = {} # empty dictionary for this edge\n",
    "        link_dict[\"source\"] = \"P\" + str(i) # attached to this paper\n",
    "        try:\n",
    "            link_dict[\"target\"] = \"A\" + str(listOfAuthors.index(authors)) # and attached to co-author\n",
    "            link_list.append(link_dict)    # save it into the list\n",
    "        except ValueError:\n",
    "            pass\n",
    "            #print(\"Author %s not in list, probably the ego node.\" %authors )\n",
    "    i=i+1\n",
    "\n",
    "# write into dictionary\n",
    "graph_dict = {\"nodes\" : node_list, \"links\" : link_list}\n",
    "\n",
    "\n",
    "# opening the file to write\n",
    "if outputJSONFileName:\n",
    "    # Writing JSON data\n",
    "    with open(outputJSONFileName, 'w') as f:\n",
    "        json.dump(graph_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2baa4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_xgi",
   "language": "python",
   "name": "venv_xgi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
