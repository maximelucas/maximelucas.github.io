{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7886e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "## some options\n",
    "inputBibFileName = \"../../_bibliography/papers.bib\"\n",
    "outputJSONFileName = \"collab_net.json\"\n",
    "#\n",
    "authorInformationFile = (\n",
    "    \"\"  #'authorinfoRosalindFranklin.csv' # optional co-author information\n",
    ")\n",
    "deleteEgoNode = False\n",
    "##\n",
    "\n",
    "import csv  # for loading comma seperated values\n",
    "import json  # for writing the json\n",
    "import re\n",
    "\n",
    "# import necessary libraries\n",
    "from pybtex.database.input import bibtex  # for reading the bib files\n",
    "\n",
    "\n",
    "# some auxiliary functions\n",
    "# you migth have to add further repalcement rules\n",
    "def latex2unicode(latexString):\n",
    "    \"\"\"takes the name of an author as string and return the string\n",
    "    with latex character replaced as normal string for the HTML\"\"\"\n",
    "    latexString = latexString.replace('{\\\\\"u}', \"ü\")\n",
    "    latexString = latexString.replace(\"{\\\\'o}\", \"ó\")\n",
    "    latexString = latexString.replace(\"{\\\\'a}\", \"á\")\n",
    "    latexString = latexString.replace(\"{\\\\~a}\", \"ã\")\n",
    "\n",
    "    return latexString\n",
    "\n",
    "\n",
    "# some preperation to read the bibtex file\n",
    "parser = bibtex.Parser()\n",
    "bib_data = parser.parse_file(inputBibFileName)\n",
    "\n",
    "\n",
    "listOfAuthors = []  # empty list of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34224a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfAuthors = []  # empty list of authors\n",
    "\n",
    "# go throuh all entries\n",
    "for paperKeys in bib_data.entries.keys():\n",
    "    # get the authors of this paper\n",
    "\n",
    "    # authors = bib_data.entries[paperKeys].persons['author'].split(\" and \")\n",
    "    # save them to the list of authors\n",
    "    for author in bib_data.entries[paperKeys].persons[\"author\"]:\n",
    "        listOfAuthors.append(str(author))\n",
    "\n",
    "listOfAuthors\n",
    "\n",
    "# remove * for co-first \n",
    "listOfAuthors = [author.replace(\"*\", \"\") for author in listOfAuthors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "811c6c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no optional co-author information available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if deleteEgoNode == True:\n",
    "    # we assume that the author with the most entries is the ego node and delete it\n",
    "    egoNode = max(listOfAuthors, key=listOfAuthors.count)  # returns the ego node\n",
    "    listOfAuthors = list(set(listOfAuthors))  # gets unique list of authors\n",
    "    listOfAuthors.pop(\n",
    "        listOfAuthors.index(egoNode)\n",
    "    )  # deletes it from the list of authors\n",
    "    print(\"Removing the ego node: %s \" % egoNode)\n",
    "else:\n",
    "    listOfAuthors = list(set(listOfAuthors))  # gets unique list of authors\n",
    "\n",
    "nAuthors = len(listOfAuthors)  # number of author nodes\n",
    "nPapers = len(bib_data.entries.keys())  # number of paper nodes\n",
    "\n",
    "\n",
    "# read the additional author information from the csv\n",
    "authorLinks_dict = {}  # create an empty dictionary\n",
    "authorImage_dict = {}  # create an empty dictionary\n",
    "\n",
    "try:\n",
    "    authorInfo_reader = csv.DictReader(open(authorInformationFile))\n",
    "    for row in authorInfo_reader:\n",
    "        authorLinks_dict[row[\"name\"]] = row[\"url\"]\n",
    "        authorImage_dict[row[\"name\"]] = row[\"image\"]\n",
    "except FileNotFoundError:\n",
    "    print(\"no optional co-author information available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00d8bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R. L. Peach\n",
      "N. W. Landry\n",
      "G. Cencetti\n",
      "D. Gruber\n",
      "T. Carletti\n",
      "T. Robiglio\n",
      "L. Tichit\n",
      "P. Expert\n",
      "A. Schwarze\n",
      "J. Petit\n",
      "A. Barrat\n",
      "F. Vaccarino\n",
      "S. Poetto\n",
      "M. Lucas\n",
      "A. Morris\n",
      "Y. Zhang\n",
      "F. Battiston\n",
      "L. Torres\n",
      "J. Newman\n",
      "A. Leitão\n",
      "I. Iacopini\n",
      "B. H. Habermann\n",
      "J.-G. Young\n",
      "R. Duncan\n",
      "T. A. Hersh\n",
      "M. Nurisso\n",
      "A. Patania\n",
      "G. Petri\n",
      "A. Arnaudon\n",
      "A. Stefanovska\n",
      "A. Townsend-Teague\n",
      "M. Bronstein\n",
      "V. Latora\n",
      "S. Gero\n",
      "D. Fanelli\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary reflecting the graph (there are more pythonic ways\n",
    "# possible to creat this, e.g., with zip, but this is easiest)\n",
    "\n",
    "node_list = []\n",
    "# create author nodes\n",
    "for i in range(nAuthors):\n",
    "    node_dict = {}  # create an empty dictionary for this node\n",
    "    node_dict[\"id\"] = \"A\" + str(i)\n",
    "    node_dict[\"group\"] = 0\n",
    "    # invert the name such that the given name is before the last name\n",
    "    try:  # we need this try to deal with single author papers\n",
    "        authorSplit = listOfAuthors[i].split(\",\")\n",
    "        nameThisAuthor = authorSplit[1][1::] + \" \" + authorSplit[0]\n",
    "    except:\n",
    "        authorSplit = listOfAuthors[i]\n",
    "        nameThisAuthor = authorSplit[1][1::] + \" \" + authorSplit[0]\n",
    "\n",
    "    nameThisAuthorUnicode = latex2unicode(nameThisAuthor)\n",
    "    print(nameThisAuthorUnicode)\n",
    "    node_dict[\"name\"] = nameThisAuthorUnicode\n",
    "    node_list.append(node_dict)\n",
    "    # try to set the url for this author but default is google it\n",
    "    node_dict[\"url\"] = \"https://www.google.com/search?q=\" + nameThisAuthor\n",
    "    try:\n",
    "        if authorLinks_dict[nameThisAuthor] is None:\n",
    "            raise KeyError(\"no information for this author\")\n",
    "        else:\n",
    "            node_dict[\"url\"] = authorLinks_dict[nameThisAuthor]\n",
    "    except KeyError:\n",
    "        node_dict[\"url\"] = \"https://www.google.com/search?q=\" + nameThisAuthor\n",
    "\n",
    "        # try to set a image for this author\n",
    "    try:\n",
    "        node_dict[\"image\"] = authorImage_dict[nameThisAuthor]\n",
    "    except KeyError:  # if no image jsut leave blank\n",
    "        node_dict[\"image\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e131735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the links between the nodes\n",
    "link_list = []\n",
    "i=0\n",
    "for paperKeys in bib_data.entries.keys(): # go over every paper\n",
    "    # create the paper node\n",
    "    node_dict = {} # create an empty dictionary for this node\n",
    "    node_dict[\"id\"] = \"P\" + str(i)\n",
    "    node_dict[\"group\"] = 1\n",
    "    thisPaperName = bib_data.entries[paperKeys].fields['title']\n",
    "    # remove curly bracket in paper name, remove it\n",
    "    if thisPaperName[0]=='{':\n",
    "        thisPaperName=thisPaperName[1:-1]\n",
    "    node_dict[\"name\"] =  thisPaperName\n",
    "    node_list.append(node_dict)\n",
    "\n",
    "    # set image for this paper\n",
    "    try:\n",
    "        node_dict[\"image\"] = bib_data.entries[paperKeys].fields['image']\n",
    "    except KeyError: # if no image just leave blank\n",
    "        node_dict[\"image\"] = []\n",
    "\n",
    "\n",
    "    # find the authors for this paper\n",
    "    authorsThisPaper = [str(i).split('*')[0].strip() for i in bib_data.entries[paperKeys].persons['author']]\n",
    "\n",
    "    # if the paper has a url, add it\n",
    "    try:\n",
    "        node_dict[\"url\"] = bib_data.entries[paperKeys].fields['url']\n",
    "    except KeyError: # otherwise refer to google\n",
    "        node_dict[\"url\"] = \"https://www.google.com/search?q=\" + bib_data.entries[paperKeys].fields['title']\n",
    "\n",
    "\n",
    "    for authors in authorsThisPaper:\n",
    "        link_dict = {} # empty dictionary for this edge\n",
    "        link_dict[\"source\"] = \"P\" + str(i) # attached to this paper\n",
    "        try:\n",
    "            link_dict[\"target\"] = \"A\" + str(listOfAuthors.index(authors)) # and attached to co-author\n",
    "            link_list.append(link_dict)    # save it into the list\n",
    "        except ValueError:\n",
    "            pass\n",
    "            #print(\"Author %s not in list, probably the ego node.\" %authors )\n",
    "    i=i+1\n",
    "\n",
    "# write into dictionary\n",
    "graph_dict = {\"nodes\" : node_list, \"links\" : link_list}\n",
    "\n",
    "\n",
    "# opening the file to write\n",
    "if outputJSONFileName:\n",
    "    # Writing JSON data\n",
    "    with open(outputJSONFileName, 'w') as f:\n",
    "        json.dump(graph_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2baa4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_39",
   "language": "python",
   "name": "python_39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
